{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b594809d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/intro-Machine-Learning/blob/main/classes/class_26_multiclase/class_26_multiclase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21875ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Medidas de desempeño de un Clasificador y clasificación multiclase: Clase 26 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f955712",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Obtención de los datos \n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# algoritmos de clasificación\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d15e9ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "mnist = fetch_openml('mnist_784', version = 1, as_frame = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394905a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X,y = mnist['data'], mnist['target'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885583b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conversión de `str` a `int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72e3a01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab13aa60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60_000], X[60_000:], y[:60_000], y[60_000:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b9586",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Configuramos las etiquetas para tener un detector de cincos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6746693f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_train_5 = (y_train==5)\n",
    "y_test_5 = (y_test==5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9fcb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Elijo un modelo de clasificación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5696bff1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acda321f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Instanciar la clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dbd29fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b274c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Entrenar nuestro clasificador con los datos de entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dfcb90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd_clf.fit(X_train, y_train_5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6db09de2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([X_train[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58899966",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# La validación cruzada con la medida de desempeño de la exactitud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8f6c7",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016189c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56acba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "puntajes = cross_val_score(sgd_clf, X_train, y_train_5, cv = 3, scoring = 'accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16edc2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "puntajes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edad088",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nota:  \n",
    "\n",
    "`shuffle=True` se omitió por error en versiones anteriores del libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58c035",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037eb084",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a090e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf649e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La exactitud o accuracy no es una buena medida de desempeño cuando al sesgo en las clases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885bb614",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Constitución de la matriz de confusión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ebc34c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad09284d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "100aa318",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "y_predicciones_train = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3e05d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predicciones_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283df422",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train_5, y_predicciones_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db187b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Precisión "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb4a54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ \\text{precision} = \\frac{TP}{TP + FP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f97b50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nos dice cuandas veces predijo bien en cuanto a la clase positiva "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591b135",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recall "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c600e38e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ \\text{recall} = \\frac{TP}{TP + FN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a8684",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Poder de detección del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58a43e3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "198d48b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " precision_score(y_train_5, y_predicciones_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf4dc156",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_predicciones_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a843c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora su 5 - detector no se ve tan brillante como cuando miró su exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f78ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando afirma que una imagen representa un 5, es correcta solo el 72,9% de las veces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a3fd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Además, solo detecta el 75,6% de los 5s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf74da1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Combinación de precision y recall "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4533b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* A menudo, es conveniente combinar la precisión y la recuperación en una sola métrica denominada puntuación $F_{1}$, \n",
    "\n",
    "* en particular si necesita una forma sencilla de comparar dos clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed558bda",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La puntuación $F_{1}$ es la media armónica de precisión y recuperación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c4be7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785d82a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como resultado, el clasificador solo obtendrá una puntuación alta de $F_{1}$ si tanto la recuperación como la precisión son altas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f40b70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ F_{1} = \\frac{2}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}} } = 2 \\cdot \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} = \\frac{TP}{TP + \\frac{FN + FP}{2}}   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b8ea3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para calcular la puntuación $F_{1}$, simplemente llame a la función `f1_score()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bfc81",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_predicciones_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5f48c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La puntuación $F_{1}$ favorece a los clasificadores que tienen una precisión y recuperación similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd2aea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto no siempre es lo que desea:  \n",
    "\n",
    "* en algunos contextos, lo que más le importa es la precisión, y  \n",
    "\n",
    "* en otros contextos realmente le importa recordar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c7bde",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Por ejemplo, si entrenó un clasificador para detectar videos que son seguros para los niños**, \n",
    "* probablemente preferiría un clasificador que rechace muchos videos buenos (baja recuperación)  \n",
    "* pero solo mantenga los seguros (alta precisión), \n",
    "\n",
    "* en lugar de un clasificador que tiene mucho más recall, pero permite que aparezcan algunos videos realmente malos en su producto \n",
    "\n",
    "(en tales casos, es posible que desee agregar una canalización humana para verificar la selección de videos del clasificador)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df727a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por otro lado, suponga que entrena **un clasificador para detectar ladrones en imágenes de vigilancia**:  \n",
    "\n",
    "probablemente esté bien si su clasificador tiene solo un 30 % de precisión siempre que tenga un 99 % de recuperación (claro, los guardias de seguridad recibirán algunas alertas falsas, pero casi todos los ladrones serán atrapados)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68681199",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Desafortunadamente, no puede tener las dos cosas: \n",
    "\n",
    "* aumentar la precisión reduce la recuperación y viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2b4b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto se llama equilibrio entre precisión/recuperación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41185b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compensación Precision/Recall "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170bfb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para comprender esta compensación, veamos cómo `SGDClassifier` toma sus decisiones de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06993d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para cada instancia, calcula una puntuación basada en una función de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f8396",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Si esa puntuación es mayor que un umbral, asigna la instancia a la clase positiva; \n",
    "* de lo contrario, lo asigna a la clase negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98270666",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La Figura 3-3 muestra algunos dígitos ubicados desde la puntuación más baja a la izquierda hasta la puntuación más alta a la derecha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d81f2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/intro-Machine-Learning/blob/main/classes/class_26_multiclase/figura_3_3_various_thresholds.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccfd28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose the decision threshold is positioned at the central arrow (between the two 5s): you will find 4 true positives (actual 5s) on the right of that threshold, and 1 false positive (actually a 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bb3e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Therefore, with that threshold, the precision is 80% (4 out of 5). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3106d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But out of 6 actual 5s, the classifier only detects 4, so the recall is 67% (4 out of 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c3543",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you raise the threshold (move it to the arrow on the right), the false positive (the 6) becomes a true negative, thereby increasing the precision (up to 100% in this case), but one true positive becomes a false negative, decreasing recall down to 50%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ecef3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Conversely, lowering the threshold increases recall and reduces precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c81ae8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn no le permite establecer el umbral directamente, pero le da acceso a los puntajes de decisión que utiliza para hacer predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f481afa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead of calling the classifier’s `predict()` method, you can call its `decision_function()` method, which returns a score for each instance, and then use any threshold you want to make predictions based on those scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720f0cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_scores = sgd_clf.decision_function([X[0]])\n",
    "y_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41166cab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8520e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The SGDClassifier uses a threshold equal to 0, so the previous code returns the same result as the `predict()` method (i.e., True). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a5eaf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s raise the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417474b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 8000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c8fba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This confirms that raising the threshold decreases recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66547c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The image actually represents a 5, and the classifier detects it when the threshold is 0, but it misses it when the threshold is increased to 8,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ee339",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Cómo se decide qué umbral usar? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391d8b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Primero, use la función `cross_val_predict()` para obtener **los puntajes** de todas las instancias en el conjunto de entrenamiento,  \n",
    "\n",
    "* pero esta vez especifique que desea obtener puntajes de decisión en lugar de predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96ce86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c92561",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With these scores, use the `precision_recall_curve()` function to compute precision and recall for all possible thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ef71c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4961a61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finalmente, use Matplotlib para trazar la precisión y recordar como funciones del valor del umbral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e602cc8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.grid() \n",
    "    plt.legend() \n",
    "    plt.xlabel('umbrales')\n",
    "    [...] # highlight the threshold and add the legend, axis label, and grid\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82602bd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/intro-Machine-Learning/blob/main/classes/class_26_multiclase/figura_3_4_thresholds.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d8508",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f724573",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quizás se pregunte por qué la curva de precisión es más irregular que la curva de recuperación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b356c1c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The reason is that precision may sometimes go down when you raise the threshold (although in general it will go up). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a91ab6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para entender por qué, vuelva a mirar la Figura de puntajes crecientes y observe lo que sucede cuando comienza desde el umbral central y lo mueve solo un dígito a la derecha:   \n",
    "\n",
    "* la precisión va de 4/5 (80 %) a 3/4 (75 %). )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135323f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por otro lado, la recuperación solo puede disminuir cuando se aumenta el umbral, lo que explica por qué su curva parece suave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333225e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gráfica de Precisión versus recuerdo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dde08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Otra forma de seleccionar una buena compensación de precisión/recuperación es trazar la precisión directamente contra la recuperación, como se muestra en la siguiente figura (se resalta el mismo umbral que antes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83bae9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/intro-Machine-Learning/blob/main/classes/class_26_multiclase/figura_3_5_recall_precision.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed56e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Puede ver que la precisión realmente comienza a caer bruscamente alrededor del 80% de recuperación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca0b77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You will probably want to select a precision/recall trade-off just before that drop—for example, at around 60% recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576761da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But of course, the choice depends on your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f29964",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose you decide to aim for 90% precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f299e8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You look up the first plot and find that you need to use a threshold of about 8,000. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2d209",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Configurar el modelo para tener un 90% de precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462a34e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Para ser más preciso, puede buscar el umbral más bajo que le proporcione al menos un $90 \\%$ de precisión. \n",
    "\n",
    "* (`np.argmax()` le dará el primer índice del valor máximo, que en este caso significa el primer valor Verdadero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c6ced",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)] # ~7816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec7da2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To make predictions (on the training set for now), instead of calling the classifier’s predict() method, you can run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4ce31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_train_pred_90 = (y_scores >= threshold_90_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c26f41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s check these predictions’ precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4feae1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "precision_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c228e5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c760dc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Great, you have a 90% precision classifier! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda7047",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see, it is fairly easy to create a classifier with virtually any precision you want: just set a high enough threshold, and you’re done. But wait, not so fast. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e405cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A high-precision classifier is not very useful if its recall is too low!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f358d28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sigerencia "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be401ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si alguien dice: \"Lleguemos al $99 \\%$ de precisión\", debe preguntar: \"¿Con qué recuperación?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099fc83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7527482",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La curva de **Características Operativas del Receptor (ROC)** es otra herramienta común utilizada con clasificadores binarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2423e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is very similar to the precision/recall curve, but instead of plotting precision versus recall, the ROC curve plots the true positive rate (another name for recall) against the false positive rate (FPR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a6ceb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The FPR is the ratio of negative instances that are incorrectly classified as positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71f61f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is equal to 1 – the true negative rate (TNR), which is the ratio of negative instances that are correctly classified as negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef95dfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The TNR is also called specificity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ef25e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hence, the ROC curve plots sensitivity (recall) versus 1 – specificity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928058f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To plot the ROC curve, you first use the `roc_curve()` function to compute the TPR and FPR for various threshold values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb754412",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d15993",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then you can plot the FPR against the TPR using Matplotlib. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce11b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This code produces the plot in Figure 3-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d0bfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\n",
    "    [...] # Add axis labels and grid\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90d985",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once again there is a trade-off: the higher the recall (TPR), the more false positives (FPR) the classifier produces. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615ca40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d958661",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/intro-Machine-Learning/blob/main/classes/class_26_multiclase/figura_3_6_false_positive_rate_vs_true_positive_rate.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856456df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way to compare classifiers is to measure the area under the curve (AUC). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628cf37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5. Scikit-Learn provides a function to compute the ROC AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbea770",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6132d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d2de6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since the ROC curve is so similar to the precision/recall (PR) curve, you may wonder how to decide which one to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd99ecb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As a rule of thumb, you should prefer the PR curve whenever the positive class is rare or when you care more about the false positives than the false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759248d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Otherwise, use the ROC curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06247780",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, looking at the previous ROC curve (and the ROC AUC score), you may think that the classifier is really good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e2b4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But this is mostly because there are few positives (5s) compared to the negatives (non- 5s). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68fe2f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In contrast, the PR curve makes it clear that the classifier has room for improvement\n",
    "(the curve could be closer to the top-left corner)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa987fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s now train a RandomForestClassifier and compare its ROC curve and ROC AUC score to those of the SGDClassifier. First, you need to get scores for each instance in the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b18af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But due to the way it works (see Chapter 7), the RandomForestClassifier class does not have a\n",
    "decision_function() method. Instead, it has a predict_proba() method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b391a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn classifiers generally have one or the other, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb92619",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The predict_proba() method returns an array containing a row per\n",
    "instance and a column per class, each containing the probability that the\n",
    "given instance belongs to the given class (e.g., 70% chance that the image\n",
    "represents a 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e6d5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
    "                                     method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4bc99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The roc_curve() function expects labels and scores, but instead of scores you can give it class probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88657b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s use the positive class’s probability as the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b42722",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest =\n",
    "roc_curve(y_train_5,y_scores_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc47637",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you are ready to plot the ROC curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc4860",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is useful to plot the first ROC curve as well to see how they compare (Figure 3-7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cb322",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89f89e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/intro-Machine-Learning/blob/main/classes/class_26_multiclase/figura_3_7_sgd_random_forest.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a073f6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see in Figure 3-7, the RandomForestClassifier’s ROC curve looks much better than the SGDClassifier’s: it comes much closer to the top-left corner. As a result, its ROC AUC score is also significantly better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c790ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5e7ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try measuring the precision and recall scores: you should find 99.0% precision and 86.6% recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40a33e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusión acerca de los clasificadores binarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f15207",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora sabe **cómo entrenar clasificadores binarios**, \n",
    "\n",
    "* elegir la métrica adecuada para su tarea,   \n",
    "* evaluar sus clasificadores mediante validación cruzada,   \n",
    "* seleccionar la compensación de precisión/recuperación que se ajuste a sus necesidades y   \n",
    "* usar curvas ROC y puntajes ROC AUC para comparar varios modelos. ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ce51e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let’s try to detect more than just the 5s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34ebeb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57b7bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mientras que los clasificadores binarios distinguen entre dos clases, \n",
    "\n",
    "* los clasificadores multiclase (también llamados clasificadores multinomiales) pueden distinguir entre más de dos clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b623a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some algorithms (such as SGD classifiers, Random Forest classifiers, and naive Bayes classifiers) are capable of handling multiple classes natively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc637081",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Others (such as Logistic Regression or Support Vector Machine classifiers) are strictly binary classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e484e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, there are various strategies that you\n",
    "can use to perform multiclass classification with multiple binary classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0db0e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way to create a system that can classify the digit images into 10 classes (from 0 to 9) is to train 10 binary classifiers, one for each digit (a 0-detector, a 1-detector, a 2-detector, and so on). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d914db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then when you want to classify an image, you get the decision score from each classifier for that image and you select the class whose classifier outputs the highest score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776ab04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is called the one-versus-the-rest (OvR) strategy (also called one-versus-all)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e5ccd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another strategy is to train a binary classifier for every pair of digits: one to distinguish 0s and 1s, another to distinguish 0s and 2s, another for 1s and 2s, and so on. This is called the one-versus-one (OvO) strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec1e1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si hay $N$ clases, necesita entrenar $ N \\times (N – 1) / 2 $ clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50105584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For the MNIST problem, this means training 45 binary classifiers! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867494e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When you want to classify an image, you have to run the image through all 45 classifiers and\n",
    "see which class wins the most duels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3b211",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The main advantage of OvO is that each classifier only needs to be trained on the part of the training set for the two classes that it must distinguish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641a157",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some algorithms (such as Support Vector Machine classifiers) scale poorly with the size of the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71259ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For these algorithms OvO is preferred because it is faster to train many classifiers on small training sets than to train few classifiers on large training sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e58e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For most binary classification algorithms, however, OvR is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4230d806",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn detects when you try to use a binary classification algorithm for a multiclass classification task, and it automatically runs OvR or OvO, depending on the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ab5ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s try this with a Support Vector Machine classifier (see Chapter 5), using the sklearn.svm.SVC class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953daa85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train) # y_train, not y_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec3da3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "svm_clf.predict([X[:5]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b412d8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That was easy! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c731d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este código entrena al SVC en el conjunto de entrenamiento usando las clases de destino originales de 0 a 9 (y_train), en lugar de las clases de destino de 5 contra el resto (y_train_5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51bd71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then it makes a prediction (a correct one in this case). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2a80f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Under the hood, Scikit-Learn actually used the OvO strategy: it trained 45 binary classifiers, got their decision scores for the image, and selected the class that won the most duels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bbd346",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you call the `decision_function()` method, you will see that it returns 10 scores per instance (instead of just 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c62006",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That’s one score per class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409c812",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "some_digit_scores = svm_clf.decision_function(X[:5])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a498f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The highest score is indeed the one corresponding to class 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d71ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaeb578",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> svm_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48635688",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "svm_clf.classes_[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29def2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad5590",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When a classifier is trained, it stores the list of target classes in its classes_ attribute,\n",
    "ordered by value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03494e50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this case, the index of each class in the classes_ array conveniently matches the class itself (e.g., the class at index 5 happens to be class 5), but in general you won’t be so lucky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540cb3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to force Scikit-Learn to use one-versus-one or one-versus-therest,\n",
    "you can use the OneVsOneClassifier or OneVsRestClassifier classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16fc69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simply create an instance and pass a classifier to its constructor (it does not even have to be a binary classifier). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56512a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, this code creates a multiclass classifier using the OvR strategy, based on an SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337af7d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC())\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "ovr_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d2e9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> len(ovr_clf.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac1791",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training an SGDClassifier (or a RandomForestClassifier) is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2ca36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> sgd_clf.fit(X_train, y_train)\n",
    ">>> sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ada45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This time Scikit-Learn did not have to run OvR or OvO because SGD classifiers can directly classify instances into multiple classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2a633",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The decision_function() method now returns one value per class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57419f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s look at the score that the SGD classifier assigned to each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d26f51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> sgd_clf.decision_function([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bcf0e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can see that the classifier is fairly confident about its prediction: almost all scores are largely negative, while class 5 has a score of 2412.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a331f79",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The model has a slight doubt regarding class 3, which gets a score of 573.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955d20a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now of course you want to evaluate this classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15fb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As usual, you can use cross-validation. Use the cross_val_score() function to evaluate the\n",
    "SGDClassifier’s accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac46d6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea8a2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It gets over 84% on all test folds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a178c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you used a random classifier, you would get 10% accuracy, so this is not such a bad score, but you can still do much better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdef23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simply scaling the inputs (as discussed in Chapter 2) increases accuracy above 89%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e69b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94d37d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d36c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If this were a real project, you would now follow the steps in your Machine Learning project checklist (see Appendix B). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef0be6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You’d explore data preparation options, try out multiple models (shortlisting the best ones and fine-tuning their hyperparameters using GridSearchCV), and automate as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3290634",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, we will assume that you have found a promising model and you want to find ways to improve it. One way to do this is to analyze the types of errors it makes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9bacb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, look at the confusion matrix. You need to make predictions using the cross_val_predict() function, then call the confusion_matrix() function, just like you did earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffc67d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    ">>> conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    ">>> conf_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229828b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That’s a lot of numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366b57b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It’s often more convenient to look at an image representation of the confusion matrix, using Matplotlib’s matshow() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b19401",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3216b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This confusion matrix looks pretty good, since most images are on the main diagonal, which means that they were classified correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24603f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The 5s look slightly darker than the other digits, which could mean that there are fewer images of 5s in the dataset or that the classifier does not perform as well on 5s as on other digits. In fact, you can verify that both are the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43861912",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s focus the plot on the errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe24de9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, you need to divide each value in the confusion matrix by the number of images in the corresponding class so that you can compare error rates instead of absolute numbers of errors (which would make abundant classes look unfairly bad):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde9d78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283273c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fill the diagonal with zeros to keep only the errors, and plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fba2ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea3eaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can clearly see the kinds of errors the classifier makes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e13f25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember that rows represent actual classes, while columns represent predicted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd262f1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The column for class 8 is quite bright, which tells you that many images get misclassified as 8s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a7bd7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, the row for class 8 is not that bad, telling you that actual 8s in general get properly classified as 8s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87023a8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see, the confusion matrix is not necessarily symmetrical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66ddf68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can also see that 3s and 5s often get confused (in both directions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f9c87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Analyzing the confusion matrix often gives you insights into ways to\n",
    "improve your classifier. Looking at this plot, it seems that your efforts\n",
    "should be spent on reducing the false 8s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd2f6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, you could try to gather more training data for digits that look like 8s (but are not) so that the classifier can learn to distinguish them from real 8s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85541b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or you could engineer new features that would help the classifier—for example, writing an\n",
    "algorithm to count the number of closed loops (e.g., 8 has two, 6 has one, 5 has none). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551dc422",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or you could preprocess the images (e.g., using Scikit-Image, Pillow, or OpenCV) to make some patterns, such as closed loops, stand out more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31831ef1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Analyzing individual errors can also be a good way to gain insights on what\n",
    "your classifier is doing and why it is failing, but it is more difficult and\n",
    "time-consuming. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778594a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, let’s plot examples of 3s and 5s (the plot_digits() function just uses Matplotlib’s imshow() function; see this chapter’s Jupyter notebook for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be34c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cl_a, cl_b = 3, 5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523df796",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The two 5 × 5 blocks on the left show digits classified as 3s, and the two 5 × 5 blocks on the right show images classified as 5s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0c2e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some of the digits that the classifier gets wrong (i.e., in the bottom-left and top-right blocks) are so badly written that even a human would have trouble classifying them (e.g.,\n",
    "the 5 in the first row and second column truly looks like a badly written 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e16291",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, most misclassified images seem like obvious errors to us, and it’s hard to understand why the classifier made the mistakes it did. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab47059",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The reason is that we used a simple SGDClassifier, which is a linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437602b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All it does is assign a weight per class to each pixel, and when it sees a new image it just sums up the weighted pixel intensities to get a score for each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058f712",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So since 3s and 5s differ only by a few pixels, this model will easily confuse them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb95834",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The main difference between 3s and 5s is the position of the small line that joins the top line to the bottom arc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db57dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you draw a 3 with the junction slightly shifted to the left, the classifier might classify it as a 5, and vice versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07befe8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In other words, this classifier is quite sensitive to image shifting and rotation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48fa59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So one way to reduce the 3/5 confusion would be to preprocess the images to ensure that they are well centered and not too rotated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221b0a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This will probably help reduce other errors as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32092f9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multilabel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6f9d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Until now each instance has always been assigned to just one class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec661e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In some cases you may want your classifier to output multiple classes for each instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477259c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider a face-recognition classifier: what should it do if it recognizes several people in the same picture? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846655de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It should attach one tag per person it recognizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7903d64",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Say the classifier has been trained to recognize three faces, Alice, Bob, and Charlie. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca001cc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then when the classifier is shown a picture of Alice and Charlie, it should output [1, 0, 1] (meaning “Alice yes, Bob no, Charlie yes”). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b700fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Such a classification system that outputs multiple binary tags is called a multilabel classification system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6aaaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We won’t go into face recognition just yet, but let’s look at a simpler example, just for illustration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6be5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659617a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This code creates a y_multilabel array containing two target labels for each digit image: the first indicates whether or not the digit is large (7, 8, or 9), and the second indicates whether or not it is odd. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593470de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The next lines create a KNeighborsClassifier instance (which supports multilabel classification, though not all classifiers do), and we train it using the multiple targets array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0dafb4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you can make a prediction, and notice that it outputs two labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f85a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c7818",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And it gets it right! The digit 5 is indeed not large (False) and odd (True)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c86d03",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are many ways to evaluate a multilabel classifier, and selecting the right metric really depends on your project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3907d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One approach is to measure the $F_{1}$ score for each individual label (or any other binary classifier metric discussed earlier), then simply compute the average score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0302a2f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This code computes the average $F_{1}$ score across all labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb369abe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053603f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This assumes that all labels are equally important, however, which may not be the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c781ab4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In particular, if you have many more pictures of Alice than of Bob or Charlie, you may want to give more weight to the classifier’s score on pictures of Alice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926b907",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One simple option is to give each label a weight equal to its support (i.e., the number of instances with that target label). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d3b51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To do this, simply set average=\"weighted\" in the preceding code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b7f7de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multioutput Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609d41f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The last type of classification task we are going to discuss here is called multioutput–multiclass classification (or simply multioutput classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205b604",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is simply a generalization of multilabel classification where each label can be multiclass (i.e., it can have more than two possible values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d80259",
   "metadata": {},
   "source": [
    "To illustrate this, let’s build a system that removes noise from images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a74d16",
   "metadata": {},
   "source": [
    "It will take as input a noisy digit image, and it will (hopefully) output a clean digit image, represented as an array of pixel intensities, just like the MNIST images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2de721",
   "metadata": {},
   "source": [
    "Notice that the classifier’s output is multilabel (one label per pixel) and each label can have multiple values (pixel intensity ranges from 0 to 255). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a42b9f",
   "metadata": {},
   "source": [
    "It is thus an example of a multioutput classification system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97278ce2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54431f0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The line between classification and regression is sometimes blurry, such as in this example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8865ec99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Arguably, predicting pixel intensity is more akin to regression than to\n",
    "classification. Moreover, multioutput systems are not limited to classification tasks; you\n",
    "could even have a system that outputs multiple labels per instance, including both class\n",
    "labels and value labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f15b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s start by creating the training and test sets by taking the MNIST images\n",
    "and adding noise to their pixel intensities with NumPy’s randint()\n",
    "function. The target images will be the original images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9342a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b05b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s take a peek at an image from the test set (yes, we’re snooping on the\n",
    "test data, so you should be frowning right now):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8dc57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On the left is the noisy input image, and on the right is the clean target\n",
    "image. Now let’s train the classifier and make it clean this image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8fe2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
    "plot_digit(clean_digit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cace7c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Looks close enough to the target! This concludes our tour of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a3504",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You should now know how to select good metrics for classification tasks, pick the appropriate precision/recall trade-off, compare classifiers, and more generally build good classification systems for a variety of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbdc4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23cb009",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set.   \n",
    "\n",
    "Hint: the KNeighborsClassifier\n",
    "works quite well for this task; you just need to find good\n",
    "hyperparameter values (try a grid search on the weights and\n",
    "n_neighbors hyperparameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d757980",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeefde5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69119449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51e469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbe5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e957be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
