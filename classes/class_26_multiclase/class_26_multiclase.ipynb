{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b594809d",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/intro-Machine-Learning/blob/main/classes/class_25_desempa%C3%B1o_clasificador/class_25_medidas_desempeno_clasificador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21875ff",
   "metadata": {},
   "source": [
    "# Medidas de desempeño de un Clasificador y clasificación multiclase: Clase 26 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f955712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.datasets import fetch_openml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d15e9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "mnist = fetch_openml('mnist_784', version = 1, as_frame = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394905a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = mnist['data'], mnist['target'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1572cb0",
   "metadata": {},
   "source": [
    "# Conversión de `str` a `int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72e3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60_000], X[60_000:], y[:60_000], y[60_000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train==5)\n",
    "y_test_5 = (y_test==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "sgd_clf.fit(X_train, y_train_5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db09de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.predict(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58899966",
   "metadata": {},
   "source": [
    "# La validación cruzada con la medida de desempeño de la exactitud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8f6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016189c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "puntajes = cross_val_score(sgd_clf, X_train, y_train_5, cv = 10, scoring = 'accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16edc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "puntajes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edad088",
   "metadata": {},
   "source": [
    "Nota:  \n",
    "\n",
    "`shuffle=True` se omitió por error en versiones anteriores del libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bce17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037eb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a43e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " precision_score(y_train_5, y_predict2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_predict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1300fc5",
   "metadata": {},
   "source": [
    "Now your 5-detector does not look as shiny as it did when you looked at its accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea25a7",
   "metadata": {},
   "source": [
    "When it claims an image represents a 5, it is correct only 72.9% of the time. Moreover, it only detects 75.6% of the 5s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b87845",
   "metadata": {},
   "source": [
    "It is often convenient to combine precision and recall into a single metric called the $F_{1}$ score, in particular if you need a simple way to compare two classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f7eea",
   "metadata": {},
   "source": [
    "The $F_{1}$ score is the harmonic mean of precision and recall (Equation 3-3). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7e4df",
   "metadata": {},
   "source": [
    "Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a231e5",
   "metadata": {},
   "source": [
    "As a result, the classifier will only get a high $F_{1}$ score if both recall and precision are high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d7aaa",
   "metadata": {},
   "source": [
    "$$ F_{1} = \\frac{2}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}} } = 2 \\cdot \\frac{}{} =   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24de40f",
   "metadata": {},
   "source": [
    "To compute the $F_{1}$ score, simply call the `f1_score()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de328644",
   "metadata": {},
   "source": [
    "The F score favors classifiers that have similar precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ad505",
   "metadata": {},
   "source": [
    "This is not always what you want: in some contexts you mostly care about precision, and in other contexts you really care about recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95775e",
   "metadata": {},
   "source": [
    "For example, if you trained a classifier to detect videos that are safe for kids, you would\n",
    "probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your product (in such cases, you may even want to add a human pipeline to check the classifier’s video selection). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db7d61",
   "metadata": {},
   "source": [
    "On the other hand, suppose you train a classifier to detect shoplifters in surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (sure, the security guards will get a few false alerts, but almost all shoplifters will get\n",
    "caught)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094f80f",
   "metadata": {},
   "source": [
    "Unfortunately, you can’t have it both ways: increasing precision reduces\n",
    "recall, and vice versa. This is called the precision/recall trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a93485",
   "metadata": {},
   "source": [
    "## Precision/Recall Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655082d",
   "metadata": {},
   "source": [
    "To understand this trade-off, let’s look at how the SGDClassifier makes its classification decisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da314513",
   "metadata": {},
   "source": [
    "For each instance, it computes a score based on a decision function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a207036",
   "metadata": {},
   "source": [
    "If that score is greater than a threshold, it assigns the instance to the positive class; otherwise it assigns it to the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e085a4",
   "metadata": {},
   "source": [
    "Figure 3-3 shows a few digits positioned from the lowest score on the left to the highest score on the right. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be3f81",
   "metadata": {},
   "source": [
    "Suppose the decision threshold is positioned at the central arrow (between the two 5s): you will find 4 true positives (actual 5s) on the right of that threshold, and 1 false positive (actually a 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333b91f",
   "metadata": {},
   "source": [
    "Therefore, with that threshold, the precision is 80% (4 out of 5). But out of 6 actual 5s, the classifier only detects 4, so the recall is 67% (4 out of 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb7428",
   "metadata": {},
   "source": [
    "If you raise the threshold (move it to the arrow on the right), the false positive (the 6) becomes a true negative, thereby increasing the precision (up to 100% in this case), but one true positive becomes a false negative, decreasing recall down to 50%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283a0ba",
   "metadata": {},
   "source": [
    "Conversely, lowering the threshold increases recall and reduces precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6041b8",
   "metadata": {},
   "source": [
    "<img src = 'https://github.com/marco-canas/intro-Machine-Learning/blob/main/classes/class_26_multiclase/figura_3_3_various_thresholds.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fba433",
   "metadata": {},
   "source": [
    "Scikit-Learn does not let you set the threshold directly, but it does give you access to the decision scores that it uses to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc093e3e",
   "metadata": {},
   "source": [
    "Instead of calling the classifier’s `predict()` method, you can call its `decision_function()` method, which returns a score for each instance, and then use any threshold you want to make predictions based on those scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = sgd_clf.decision_function([X[0]])\n",
    "y_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41166cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f89c80",
   "metadata": {},
   "source": [
    "The SGDClassifier uses a threshold equal to 0, so the previous code returns the same result as the predict() method (i.e., True). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790de38",
   "metadata": {},
   "source": [
    "Let’s raise the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6343f",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> threshold = 8000\n",
    ">>> y_some_digit_pred = (y_scores > threshold)\n",
    ">>> y_some_digit_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2010a06",
   "metadata": {},
   "source": [
    "This confirms that raising the threshold decreases recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c25eb",
   "metadata": {},
   "source": [
    "The image actually represents a 5, and the classifier detects it when the threshold is 0, but it misses it when the threshold is increased to 8,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d40a0c",
   "metadata": {},
   "source": [
    "How do you decide which threshold to use? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdc01b",
   "metadata": {},
   "source": [
    "First, use the cross_val_predict() function to get the scores of all instances in the training set, but this time specify that you want to return decision scores instead of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
    "                             method=\"decision_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd794b8",
   "metadata": {},
   "source": [
    "With these scores, use the precision_recall_curve() function to compute precision and recall for all possible thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634822a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f3418a",
   "metadata": {},
   "source": [
    "Finally, use Matplotlib to plot precision and recall as functions of the threshold value (Figure 3-4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    [...] # highlight the threshold and add the legend, axis label, and grid\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4d5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d26f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ef8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
